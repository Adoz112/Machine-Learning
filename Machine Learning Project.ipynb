{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Train_folder/train/1.wav\n",
      "-----------------------------------------------\n",
      "Channels: 1\n",
      "Sample Rate: 48000\n",
      "First Sample: -3939\n",
      "Second Sample: -4940\n",
      "Length in Seconds: 4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wave\n",
    "import struct\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "\n",
    "def parse_wave_python(filename):\n",
    "    with wave.open(filename, 'rb') as wave_file:\n",
    "        sample_rate = wave_file.getframerate()\n",
    "        length_in_seconds = wave_file.getnframes() / sample_rate\n",
    "        \n",
    "        first_sample = struct.unpack(\n",
    "            '<h', wave_file.readframes(1))[0]\n",
    "        second_sample = struct.unpack(\n",
    "            '<h', wave_file.readframes(1))[0]\n",
    "    print('''\n",
    "Parsed {filename}\n",
    "-----------------------------------------------\n",
    "Channels: {num_channels}\n",
    "Sample Rate: {sample_rate}\n",
    "First Sample: {first_sample}\n",
    "Second Sample: {second_sample}\n",
    "Length in Seconds: {length_in_seconds}'''.format(\n",
    "            filename=filename,\n",
    "            num_channels=wave_file.getnchannels(),\n",
    "            sample_rate=wave_file.getframerate(),\n",
    "            first_sample=first_sample,\n",
    "            second_sample=second_sample,\n",
    "            length_in_seconds=length_in_seconds))\n",
    "        \n",
    "parse_wave_python('Train_folder/train/1.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract the useful features from sound data, we will use Librosa library\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs, chroma, mel, contrast,tonnetz = extract_feature('Train_folder/train/4316.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.03483262e+02,  4.37438912e+01,  1.62066177e+01,  2.04347375e+01,\n",
       "        2.18889983e+00,  2.40929443e+01,  8.44791575e+00,  2.73242543e+01,\n",
       "        3.93113719e+00, -6.75690264e+00,  5.98093523e+00,  1.44193967e+01,\n",
       "       -5.05454240e+00,  5.42332584e+00, -8.42011760e+00,  5.09449510e+00,\n",
       "       -1.69607206e+00, -2.25535080e+00, -1.18245267e+00, -6.55411655e+00,\n",
       "       -4.44424257e+00,  7.92568749e+00, -4.03099996e+00, -3.59425263e+00,\n",
       "       -3.16242792e-02,  7.58745412e-01,  3.59599853e-01,  1.72537591e+00,\n",
       "       -1.07468338e+00,  8.60886468e+00, -4.12876660e+00, -4.00765638e-01,\n",
       "        6.55324621e+00, -7.58209877e+00, -4.13918052e+00, -8.27819963e-01,\n",
       "       -4.91430500e+00,  5.49845310e+00, -9.06442783e+00,  5.51283659e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         Class\n",
       "0   0         siren\n",
       "1   1  street_music\n",
       "2   2      drilling\n",
       "3   3         siren\n",
       "4   4      dog_bark"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading csv file  \n",
    "df = pd.read_csv(\"Train_folder/train.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = df['Class'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavcatalog = [i for i in enumerate(lista)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'siren'),\n",
       " (1, 'street_music'),\n",
       " (2, 'drilling'),\n",
       " (3, 'dog_bark'),\n",
       " (4, 'children_playing'),\n",
       " (5, 'gun_shot'),\n",
       " (6, 'engine_idling'),\n",
       " (7, 'air_conditioner'),\n",
       " (8, 'jackhammer'),\n",
       " (9, 'car_horn')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavcatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'drilling')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get drilling\n",
    "wavcatalog[2][1]\n",
    "#get tuple (2, drilling)\n",
    "wavcatalog[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18045\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n",
      "C:\\Users\\18045\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1476: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(X < 0) or np.any(X_ref < 0):\n",
      "C:\\Users\\18045\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1488: RuntimeWarning: invalid value encountered in maximum\n",
      "  Z = np.maximum(X, X_ref).astype(dtype)\n",
      "C:\\Users\\18045\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1489: RuntimeWarning: invalid value encountered in less\n",
      "  bad_idx = (Z < np.finfo(dtype).tiny)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 300.wav didn't work\n",
      "File 1488.wav didn't work\n",
      "File 2458.wav didn't work\n"
     ]
    }
   ],
   "source": [
    "features, labels = np.empty((0,193)), np.empty(0)\n",
    "for i in range(df.shape[0]):\n",
    "   number = df.iloc[i,0]\n",
    "   label = df.iloc[i,1]\n",
    "   filename = f'{number}.wav'\n",
    "   lbl = f'{label}'\n",
    "   try:\n",
    "       mfccs, chroma, mel, contrast,tonnetz = extract_feature(f'Train_folder/train/{filename}')\n",
    "   except:\n",
    "       print(f\"File {filename} didn't work\")\n",
    "       continue\n",
    "   ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "   features = np.vstack([features,ext_features])\n",
    "   if label == wavcatalog[0][1]:\n",
    "        labels = np.append(labels, wavcatalog[0][0])\n",
    "   elif label == wavcatalog[1][1]:\n",
    "        labels = np.append(labels, wavcatalog[1][0])\n",
    "   elif label == wavcatalog[2][1]:\n",
    "        labels = np.append(labels, wavcatalog[2][0])\n",
    "   elif label == wavcatalog[3][1]:\n",
    "        labels = np.append(labels, wavcatalog[3][0])\n",
    "   elif label == wavcatalog[4][1]:\n",
    "        labels = np.append(labels, wavcatalog[4][0])\n",
    "   elif label == wavcatalog[5][1]:\n",
    "        labels = np.append(labels, wavcatalog[5][0])\n",
    "   elif label == wavcatalog[6][1]:\n",
    "        labels = np.append(labels, wavcatalog[6][0])\n",
    "   elif label == wavcatalog[7][1]:\n",
    "        labels = np.append(labels, wavcatalog[7][0])\n",
    "   elif label == wavcatalog[8][1]:\n",
    "        labels = np.append(labels, wavcatalog[8][0])\n",
    "   elif label == wavcatalog[9][1]:\n",
    "        labels = np.append(labels, wavcatalog[9][0])\n",
    "  \n",
    "   #labels = np.append(labels, fn.split('/')[2].split('-')[1])\n",
    "    #return np.array(features), np.array(labels, dtype = np.int)\n",
    "   \n",
    "   #print(chroma)\n",
    "   #print(filename)\n",
    "   #print(lbl)\n",
    "#     print(df.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., ..., 6., 6., 7.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.50957191e+01,  1.29611846e+02, -3.26698975e+01, ...,\n",
       "         1.57509179e-03, -5.37471939e-03,  5.26261495e-03],\n",
       "       [-8.35056669e+00,  1.13704109e+02, -1.91475123e+01, ...,\n",
       "        -5.36374958e-03,  2.90953126e-03, -1.54599678e-03],\n",
       "       [-1.15225264e+02,  3.67671473e+00, -3.87245168e+01, ...,\n",
       "         2.73520672e-02, -9.37955141e-03, -4.78768348e-03],\n",
       "       ...,\n",
       "       [-3.12261079e+02,  4.62412806e+01,  5.05164659e+00, ...,\n",
       "         1.62614482e-01, -3.83779053e-02, -1.89554327e-02],\n",
       "       [-2.71249094e+02,  1.33006300e+02, -2.83203666e+01, ...,\n",
       "         2.02666673e-01, -1.93794808e-02, -5.00848620e-02],\n",
       "       [-2.91026597e+02,  2.33391865e+02, -4.70676553e+00, ...,\n",
       "         5.15215980e-02,  1.03867911e-02, -1.45272843e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71283036, 0.59447857, 0.56851254, ..., 0.40620691, 0.46932733,\n",
       "        0.27467782],\n",
       "       [0.78216945, 0.54631151, 0.62625267, ..., 0.39764163, 0.52111423,\n",
       "        0.25072002],\n",
       "       [0.67114125, 0.21315939, 0.54265952, ..., 0.43802591, 0.44429214,\n",
       "        0.23931333],\n",
       "       ...,\n",
       "       [0.46644797, 0.34204071, 0.72958225, ..., 0.60499331, 0.26301626,\n",
       "        0.18946056],\n",
       "       [0.50905382, 0.60475664, 0.58708489, ..., 0.65443357, 0.38178011,\n",
       "        0.07992387],\n",
       "       [0.4885077 , 0.90871424, 0.68791416, ..., 0.46786068, 0.56785643,\n",
       "        0.20504211]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Layers\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(193,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                3104      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,978\n",
      "Trainable params: 3,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\18045\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4888 samples, validate on 544 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 2.2925 - acc: 0.1066 - val_loss: 2.2689 - val_acc: 0.1250\n",
      "Epoch 2/20\n",
      " - 1s - loss: 2.2556 - acc: 0.1418 - val_loss: 2.2389 - val_acc: 0.1507\n",
      "Epoch 3/20\n",
      " - 1s - loss: 2.2198 - acc: 0.2013 - val_loss: 2.2030 - val_acc: 0.2022\n",
      "Epoch 4/20\n",
      " - 1s - loss: 2.1825 - acc: 0.2306 - val_loss: 2.1647 - val_acc: 0.2408\n",
      "Epoch 5/20\n",
      " - 1s - loss: 2.1410 - acc: 0.2477 - val_loss: 2.1235 - val_acc: 0.2904\n",
      "Epoch 6/20\n",
      " - 1s - loss: 2.0951 - acc: 0.2680 - val_loss: 2.0752 - val_acc: 0.3125\n",
      "Epoch 7/20\n",
      " - 1s - loss: 2.0442 - acc: 0.2968 - val_loss: 2.0215 - val_acc: 0.3456\n",
      "Epoch 8/20\n",
      " - 1s - loss: 1.9864 - acc: 0.3343 - val_loss: 1.9672 - val_acc: 0.3382\n",
      "Epoch 9/20\n",
      " - 1s - loss: 1.9360 - acc: 0.3566 - val_loss: 1.9211 - val_acc: 0.3529\n",
      "Epoch 10/20\n",
      " - 1s - loss: 1.8952 - acc: 0.3791 - val_loss: 1.8873 - val_acc: 0.3493\n",
      "Epoch 11/20\n",
      " - 1s - loss: 1.8608 - acc: 0.3832 - val_loss: 1.8544 - val_acc: 0.4099\n",
      "Epoch 12/20\n",
      " - 1s - loss: 1.8306 - acc: 0.4004 - val_loss: 1.8284 - val_acc: 0.4320\n",
      "Epoch 13/20\n",
      " - 1s - loss: 1.8046 - acc: 0.4045 - val_loss: 1.8043 - val_acc: 0.4173\n",
      "Epoch 14/20\n",
      " - 1s - loss: 1.7806 - acc: 0.4067 - val_loss: 1.7856 - val_acc: 0.4338\n",
      "Epoch 15/20\n",
      " - 1s - loss: 1.7594 - acc: 0.4184 - val_loss: 1.7638 - val_acc: 0.4210\n",
      "Epoch 16/20\n",
      " - 1s - loss: 1.7367 - acc: 0.4259 - val_loss: 1.7428 - val_acc: 0.4338\n",
      "Epoch 17/20\n",
      " - 1s - loss: 1.7176 - acc: 0.4374 - val_loss: 1.7264 - val_acc: 0.4301\n",
      "Epoch 18/20\n",
      " - 1s - loss: 1.6978 - acc: 0.4409 - val_loss: 1.7108 - val_acc: 0.4651\n",
      "Epoch 19/20\n",
      " - 1s - loss: 1.6780 - acc: 0.4489 - val_loss: 1.6860 - val_acc: 0.4706\n",
      "Epoch 20/20\n",
      " - 1s - loss: 1.6580 - acc: 0.4546 - val_loss: 1.6698 - val_acc: 0.4614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112714e3d68>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation loss should go down and validation accuracy goes up (which should be close to 1)\n",
    "#Model has been trained to a .46 percent accuracy rate (that the data is categorized correctly ) \n",
    "#Increasing the Epoch to get closer to 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
